{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "pos_data_path = BASE_DIR + '/pos.txt'\n",
    "neg_data_path = BASE_DIR + '/neg.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(pos_data_path, 'r') as f:\n",
    "    pos_data = f.read()\n",
    "with open(neg_data_path, 'r') as f:\n",
    "    neg_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "for l in pos_data.split('\\n'):\n",
    "    lines.append(l)\n",
    "for l in neg_data.split('\\n'):\n",
    "    lines.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "class FeatureName(Enum):\n",
    "    VERB = auto() # does this sentence contain a VB*?\n",
    "    FOLLOWING = auto() # is the following word a <POS>? postfixed with _<POS>\n",
    "    VERB_CHILD_DEP = auto() # what are the child (outgoing edges) dependencies (arc labels)? postfixed with _<DEP>\n",
    "    VERB_HEAD_DEP = auto() # what are the head (incoming edge) dependencies (arc labels)? postfixed with _<DEP>\n",
    "    VERB_CHILD_POS = auto() # is the child dependency a <POS>? postfixed with _<POS>\n",
    "    VERB_HEAD_POS = auto() # is the head dependency a <POS>? postfixed with _<POS>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [s for l in lines for s in sent_tokenize(l)] # punkt\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sentences = []\n",
    "for s in sentences:\n",
    "    words = word_tokenize(s)\n",
    "    tagged = nltk.pos_tag(words) # averaged_perceptron_tagger\n",
    "    tagged_sentences.append(tagged)\n",
    "print(tagged_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: POS accuracy\n",
    "\n",
    "`Run down to the shop, will you, Peter` is parsed unexpectedly by `nltk.pos_tag`:\n",
    "> `[('Run', 'NNP'), ('down', 'RB'), ('to', 'TO'), ('the', 'DT'), ('shop', 'NN'), (',', ','), ('will', 'MD'), ('you', 'PRP'), (',', ','), ('Peter', 'NNP')]`\n",
    "\n",
    "`Run` is tagged as a `NNP (proper noun, singular)`\n",
    "\n",
    "I expected an output more like what the [Stanford Parser](http://nlp.stanford.edu:8080/parser/) provides:\n",
    "> `Run/VBG down/RP to/TO the/DT shop/NN ,/, will/MD you/PRP ,/, Peter/NNP`\n",
    "\n",
    "`Run` is tagged as a `VGB (verb, gerund/present participle)` - still not quite the `VB` I want, but at least it's a `V*`\n",
    "\n",
    "_MEANWHILE..._\n",
    "\n",
    "`nltk.pos_tag` did better with:\n",
    "> `[('Do', 'VB'), ('not', 'RB'), ('clean', 'VB'), ('soot', 'NN'), ('off', 'IN'), ('the', 'DT'), ('window', 'NN')]`\n",
    "\n",
    "Compared to [Stanford CoreNLP](http://nlp.stanford.edu:8080/corenlp/process) (note that this is different than what [Stanford Parser](http://nlp.stanford.edu:8080/parser/) outputs):\n",
    "> `(ROOT (S (VP (VB Do) (NP (RB not) (JJ clean) (NN soot)) (PP (IN off) (NP (DT the) (NN window))))))`\n",
    "\n",
    "Concern: _clean_ as `VB (verb, base form)` vs `JJ (adjective)` \n",
    "\n",
    "**IMPROVE** POS taggers should vote: nltk.pos_tag (averaged_perceptron_tagger), Stanford Parser, CoreNLP, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "featuresets = []\n",
    "for ts in tagged_sentences:\n",
    "    s_features = defaultdict(int)\n",
    "    for idx, tup in enumerate(ts):\n",
    "        #print(tup)\n",
    "        pos = tup[1]\n",
    "        # FeatureName.VERB\n",
    "        is_verb = re.match(r'VB.?', pos) is not None\n",
    "        print(tup, is_verb)\n",
    "        if is_verb:\n",
    "            s_features[FeatureName.VERB] += 1\n",
    "            # FOLLOWING_POS\n",
    "            next_idx = idx + 1;\n",
    "            if next_idx < len(ts):\n",
    "                s_features[f'{FeatureName.FOLLOWING}_{ts[next_idx][1]}'] += 1\n",
    "            # VERB_MODIFIER\n",
    "            # VERB_MODIFYING\n",
    "        else:\n",
    "            s_features[FeatureName.VERB] = 0\n",
    "    featuresets.append(dict(s_features))\n",
    "\n",
    "print()\n",
    "print(featuresets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I need a library that supports dependency parsing, which NLTK does not..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [spaCy.io](https://spacy.io/)\n",
    "_Because Stanford NLP is hard to install_\n",
    "\n",
    "<img src=\"nltk_library_comparison.png\" alt=\"NLTK library comparison chart\" style=\"width: 400px; margin: 0;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!conda config --add channels conda-forge\n",
    "!conda install spacy\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Spacy Data Model for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens.doc import Doc\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy's sentence segmentation is lacking... https://github.com/explosion/spaCy/issues/235. So each '\\n' will start a new Spacy Doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Be kind,\n",
       " Get out of here,\n",
       " Look this over,\n",
       " Paul, do your homework now,\n",
       " Do not clean soot off the window,\n",
       " Turn your phones off, please,\n",
       " Run down to the shop, will you, Peter,\n",
       " Look at this,\n",
       " Help is on the way,\n",
       " I can't feel my face when I'm with you,\n",
       " Will you marry me?]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [nlp(line) for line in lines]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collapse noun phrases into single compounds\n",
    "for doc in docs:\n",
    "    for np in doc.noun_chunks:\n",
    "        np.merge(np.root.tag_, np.text, np.root.ent_type_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization, POS tagging, and syntactic parsing happened automatically with the `nlp(line)` calls above! So let's look at these outputs.\n",
    "\n",
    "https://spacy.io/docs/usage/data-model and https://spacy.io/docs/api/doc will be useful going forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Be kind]\n",
      "[Get out of here]\n",
      "[Look this over]\n",
      "[Paul, do your homework now]\n",
      "[Do not clean soot off the window]\n",
      "[Turn your phones off, please]\n",
      "[Run down to the shop, will you, Peter]\n",
      "[Look at this]\n",
      "[Help is on the way]\n",
      "[I can't feel my face when I'm with you]\n",
      "[Will you marry me?]\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(list(doc.sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[Paul, your homework]\n",
      "[soot, the window]\n",
      "[your phones]\n",
      "[the shop, you]\n",
      "[]\n",
      "[Help, the way]\n",
      "[I, my face, I, you]\n",
      "[you, me]\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(list(doc.noun_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Spacy's dependency graph visualization](https://demos.explosion.ai/displacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Be ROOT be VERB VB Be [kind]\n",
      "kind acomp kind ADJ JJ Be []\n",
      "Get ROOT get VERB VB Get [out]\n",
      "out prep out ADP IN Get [of]\n",
      "of prep of ADP IN out [here]\n",
      "here pcomp here ADV RB of []\n",
      "Look ROOT look VERB VB Look [this, over]\n",
      "this dobj this DET DT Look []\n",
      "over prep over ADP IN Look []\n",
      "Paul nsubj Paul PROPN NNP do [,]\n",
      ", punct , PUNCT , Paul []\n",
      "do ROOT do VERB VB do [Paul, your homework, now]\n",
      "your homework dobj your homework NOUN NN do []\n",
      "now advmod now ADV RB do []\n",
      "Do ROOT do VERB VBP Do [clean]\n",
      "not neg not ADV RB clean []\n",
      "clean acomp clean ADJ JJ Do [not, soot]\n",
      "soot dobj soot NOUN NN clean [off]\n",
      "off prep off ADP IN soot [the window]\n",
      "the window pobj the window NOUN NN off []\n",
      "Turn ROOT turn VERB VB Turn [your phones, off, ,, please]\n",
      "your phones dobj your phones NOUN NNS Turn []\n",
      "off prt off PART RP Turn []\n",
      ", punct , PUNCT , Turn []\n",
      "please intj please INTJ UH Turn []\n",
      "Run ROOT run VERB VB Run [down, to, ,, will]\n",
      "down prt down PART RP Run []\n",
      "to prep to ADP IN Run [the shop]\n",
      "the shop pobj the shop NOUN NN to []\n",
      ", punct , PUNCT , Run []\n",
      "will conj will VERB MD Run [you]\n",
      "you nsubj you PRON PRP will [,, Peter]\n",
      ", punct , PUNCT , you []\n",
      "Peter appos peter PROPN NNP you []\n",
      "Look ROOT look VERB VB Look [at]\n",
      "at prep at ADP IN Look [this]\n",
      "this pobj this DET DT at []\n",
      "Help nsubj Help NOUN NN is []\n",
      "is ROOT be VERB VBZ is [Help, on]\n",
      "on prep on ADP IN is [the way]\n",
      "the way pobj the way NOUN NN on []\n",
      "I nsubj I PRON PRP feel []\n",
      "ca aux can VERB MD feel []\n",
      "n't neg not ADV RB feel []\n",
      "feel ROOT feel VERB VB feel [I, ca, n't, my face, 'm]\n",
      "my face dobj my face NOUN NN feel []\n",
      "when advmod when ADV WRB 'm []\n",
      "I nsubj I PRON PRP 'm []\n",
      "'m advcl be VERB VBP feel [when, I, with]\n",
      "with prep with ADP IN 'm [you]\n",
      "you pobj you PRON PRP with []\n",
      "Will aux will VERB MD marry []\n",
      "you nsubj you PRON PRP marry []\n",
      "marry ROOT marry VERB VB marry [Will, you, me, ?]\n",
      "me dobj me PRON PRP marry []\n",
      "? punct ? PUNCT . marry []\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    for token in doc:\n",
    "        print(token.text, token.dep_, token.lemma_, token.pos_, token.tag_, token.head, list(token.children))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note what Spacy POS tagger did with `Run down to the shop, will you Peter`:\n",
    "\n",
    "`Run/VB down/RP to/IN the shop/NN ,/, will/MD you/PRP ,/, Peter/NNP`\n",
    "\n",
    "where `Run` is the `VB` I expected earlier from POS tagging. Also note that `the shop` has been collapsed to a single compound, which will be helpful during featurization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Be VERB VB\n",
      "kind ADJ JJ\n",
      "{<FeatureName.VERB: 1>: 1, 'FeatureName.FOLLOWING_JJ': 1, 'FeatureName.VERB_CHILD_DEP_ACOMP': 1, 'FeatureName.VERB_CHILD_POS_JJ': 1}\n",
      "\n",
      "Get VERB VB\n",
      "out ADP IN\n",
      "of ADP IN\n",
      "here ADV RB\n",
      "{<FeatureName.VERB: 1>: 1, 'FeatureName.FOLLOWING_IN': 1, 'FeatureName.VERB_CHILD_DEP_PREP': 1, 'FeatureName.VERB_CHILD_POS_IN': 1}\n",
      "\n",
      "Look VERB VB\n",
      "this DET DT\n",
      "over ADP IN\n",
      "{<FeatureName.VERB: 1>: 1, 'FeatureName.FOLLOWING_DT': 1, 'FeatureName.VERB_CHILD_DEP_DOBJ': 1, 'FeatureName.VERB_CHILD_POS_DT': 1, 'FeatureName.VERB_CHILD_DEP_PREP': 1, 'FeatureName.VERB_CHILD_POS_IN': 1}\n",
      "\n",
      "Paul PROPN NNP\n",
      ", PUNCT ,\n",
      "do VERB VB\n",
      "your homework NOUN NN\n",
      "now ADV RB\n",
      "{<FeatureName.VERB: 1>: 1, 'FeatureName.FOLLOWING_NN': 1, 'FeatureName.VERB_CHILD_DEP_NSUBJ': 1, 'FeatureName.VERB_CHILD_POS_NNP': 1, 'FeatureName.VERB_CHILD_DEP_DOBJ': 1, 'FeatureName.VERB_CHILD_POS_NN': 1, 'FeatureName.VERB_CHILD_DEP_ADVMOD': 1, 'FeatureName.VERB_CHILD_POS_RB': 1}\n",
      "\n",
      "Do VERB VBP\n",
      "not ADV RB\n",
      "clean ADJ JJ\n",
      "soot NOUN NN\n",
      "off ADP IN\n",
      "the window NOUN NN\n",
      "{<FeatureName.VERB: 1>: 1, 'FeatureName.FOLLOWING_RB': 1, 'FeatureName.VERB_CHILD_DEP_ACOMP': 1, 'FeatureName.VERB_CHILD_POS_JJ': 1}\n",
      "\n",
      "Turn VERB VB\n",
      "your phones NOUN NNS\n",
      "off PART RP\n",
      ", PUNCT ,\n",
      "please INTJ UH\n",
      "{<FeatureName.VERB: 1>: 1, 'FeatureName.FOLLOWING_NNS': 1, 'FeatureName.VERB_CHILD_DEP_DOBJ': 1, 'FeatureName.VERB_CHILD_POS_NNS': 1, 'FeatureName.VERB_CHILD_DEP_PRT': 1, 'FeatureName.VERB_CHILD_POS_RP': 1, 'FeatureName.VERB_CHILD_DEP_PUNCT': 1, 'FeatureName.VERB_CHILD_POS_,': 1, 'FeatureName.VERB_CHILD_DEP_INTJ': 1, 'FeatureName.VERB_CHILD_POS_UH': 1}\n",
      "\n",
      "Run VERB VB\n",
      "down PART RP\n",
      "to ADP IN\n",
      "the shop NOUN NN\n",
      ", PUNCT ,\n",
      "will VERB MD\n",
      "you PRON PRP\n",
      ", PUNCT ,\n",
      "Peter PROPN NNP\n",
      "{<FeatureName.VERB: 1>: 1, 'FeatureName.FOLLOWING_RP': 1, 'FeatureName.VERB_CHILD_DEP_PRT': 1, 'FeatureName.VERB_CHILD_POS_RP': 1, 'FeatureName.VERB_CHILD_DEP_PREP': 1, 'FeatureName.VERB_CHILD_POS_IN': 1, 'FeatureName.VERB_CHILD_DEP_PUNCT': 1, 'FeatureName.VERB_CHILD_POS_,': 1, 'FeatureName.VERB_CHILD_DEP_CONJ': 1, 'FeatureName.VERB_CHILD_POS_MD': 1}\n",
      "\n",
      "Look VERB VB\n",
      "at ADP IN\n",
      "this DET DT\n",
      "{<FeatureName.VERB: 1>: 1, 'FeatureName.FOLLOWING_IN': 1, 'FeatureName.VERB_CHILD_DEP_PREP': 1, 'FeatureName.VERB_CHILD_POS_IN': 1}\n",
      "\n",
      "Help NOUN NN\n",
      "is VERB VBZ\n",
      "on ADP IN\n",
      "the way NOUN NN\n",
      "{<FeatureName.VERB: 1>: 1, 'FeatureName.FOLLOWING_IN': 1, 'FeatureName.VERB_CHILD_DEP_NSUBJ': 1, 'FeatureName.VERB_CHILD_POS_NN': 1, 'FeatureName.VERB_CHILD_DEP_PREP': 1, 'FeatureName.VERB_CHILD_POS_IN': 1}\n",
      "\n",
      "I PRON PRP\n",
      "ca VERB MD\n",
      "n't ADV RB\n",
      "feel VERB VB\n",
      "my face NOUN NN\n",
      "when ADV WRB\n",
      "I PRON PRP\n",
      "'m VERB VBP\n",
      "with ADP IN\n",
      "you PRON PRP\n",
      "{<FeatureName.VERB: 1>: 2, 'FeatureName.FOLLOWING_NN': 1, 'FeatureName.VERB_CHILD_DEP_NSUBJ': 2, 'FeatureName.VERB_CHILD_POS_PRP': 2, 'FeatureName.VERB_CHILD_DEP_AUX': 1, 'FeatureName.VERB_CHILD_POS_MD': 1, 'FeatureName.VERB_CHILD_DEP_NEG': 1, 'FeatureName.VERB_CHILD_POS_RB': 1, 'FeatureName.VERB_CHILD_DEP_DOBJ': 1, 'FeatureName.VERB_CHILD_POS_NN': 1, 'FeatureName.VERB_CHILD_DEP_ADVCL': 1, 'FeatureName.VERB_CHILD_POS_VBP': 1, 'FeatureName.FOLLOWING_IN': 1, 'FeatureName.VERB_HEAD_DEP_ROOT': 1, 'FeatureName.VERB_HEAD_POS_VB': 1, 'FeatureName.VERB_CHILD_DEP_ADVMOD': 1, 'FeatureName.VERB_CHILD_POS_WRB': 1, 'FeatureName.VERB_CHILD_DEP_PREP': 1, 'FeatureName.VERB_CHILD_POS_IN': 1}\n",
      "\n",
      "Will VERB MD\n",
      "you PRON PRP\n",
      "marry VERB VB\n",
      "me PRON PRP\n",
      "? PUNCT .\n",
      "{<FeatureName.VERB: 1>: 1, 'FeatureName.FOLLOWING_PRP': 1, 'FeatureName.VERB_CHILD_DEP_AUX': 1, 'FeatureName.VERB_CHILD_POS_MD': 1, 'FeatureName.VERB_CHILD_DEP_NSUBJ': 1, 'FeatureName.VERB_CHILD_POS_PRP': 2, 'FeatureName.VERB_CHILD_DEP_DOBJ': 1, 'FeatureName.VERB_CHILD_DEP_PUNCT': 1, 'FeatureName.VERB_CHILD_POS_.': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spacy.symbols import VERB\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "featuresets = []\n",
    "for doc in docs:\n",
    "    s_features = defaultdict(int)\n",
    "    for idx, token in enumerate(doc):\n",
    "        print(token, token.pos_, token.tag_)\n",
    "        if re.match(r'VB.?', token.tag_) is not None: # note: not using token.pos == VERB because this also includes BES, HVS, MD tags \n",
    "            s_features[FeatureName.VERB] += 1\n",
    "            # FOLLOWING_POS\n",
    "            next_idx = idx + 1;\n",
    "            if next_idx < len(doc):\n",
    "                s_features[f'{FeatureName.FOLLOWING}_{doc[next_idx].tag_}'] += 1\n",
    "            # VERB_HEAD_DEP\n",
    "            # VERB_HEAD_POS\n",
    "            '''\n",
    "            \"Because the syntactic relations form a tree, every word has exactly one head.\n",
    "            You can therefore iterate over the arcs in the tree by iterating over the words in the sentence.\"\n",
    "            https://spacy.io/docs/usage/dependency-parse#navigating\n",
    "            '''\n",
    "            if (token.head is not token):\n",
    "                s_features[f'{FeatureName.VERB_HEAD_DEP}_{token.head.dep_.upper()}'] += 1\n",
    "                s_features[f'{FeatureName.VERB_HEAD_POS}_{token.head.tag_}'] += 1\n",
    "            # VERB_CHILD_DEP\n",
    "            # VERB_CHILD_POS\n",
    "            for child in token.children:\n",
    "                s_features[f'{FeatureName.VERB_CHILD_DEP}_{child.dep_.upper()}'] += 1\n",
    "                s_features[f'{FeatureName.VERB_CHILD_POS}_{child.tag_}'] += 1            \n",
    "    if len(s_features) > 0:\n",
    "        featuresets.append(dict(s_features))\n",
    "        print(dict(s_features))\n",
    "    print()\n",
    "\n",
    "#print(featuresets, len(featuresets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things that didn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Stanford NLP](https://nlp.stanford.edu/software/)\n",
    "Setup guide used: https://stackoverflow.com/a/34112695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get dependency parser, NER, POS tagger\n",
    "!wget https://nlp.stanford.edu/software/stanford-parser-full-2017-06-09.zip\n",
    "!wget https://nlp.stanford.edu/software/stanford-ner-2017-06-09.zip\n",
    "!wget https://nlp.stanford.edu/software/stanford-postagger-full-2017-06-09.zip\n",
    "!unzip stanford-parser-full-2017-06-09.zip\n",
    "!unzip stanford-ner-2017-06-09.zip\n",
    "!unzip stanford-postagger-full-2017-06-09.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.parse.stanford import StanfordParser\n",
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "from nltk.parse.stanford import StanfordNeuralDependencyParser\n",
    "from nltk.tag.stanford import StanfordPOSTagger, StanfordNERTagger\n",
    "from nltk.tokenize.stanford import StanfordTokenizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
