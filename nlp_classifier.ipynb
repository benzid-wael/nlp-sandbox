{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP for ML Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypothesis**: Part of Speech (POS) tagging and syntactic dependency parsing provides valuable information for classifying imperative phrases. The thinking is that being able to detect imperative phrases will transfer well to detecting tasks and to-dos.\n",
    "\n",
    "#### Some Terminology\n",
    "- [_Imperative mood_](https://en.wikipedia.org/wiki/Imperative_mood) is \"used principally for ordering, requesting or advising the listener to do (or not to do) something... also often used for giving instructions as to how to perform a task.\"\n",
    "- _Part of speech (POS)_ is a way of categorizing a word based on its syntactic function.\n",
    "    - The POS tagger from Spacy.io that is used in this notebook differentiates between [*pos_* and *tag_*](https://spacy.io/docs/api/annotation#pos-tagging-english) - *POS (pos_)* refers to \"coarse-grained part-of-speech\" like `VERB`, `ADJ`, or `PUNCT`; and *POSTAG (tag_)* refers to \"fine-grained part-of-speech\" like `VB`, `JJ`, or `.`.\n",
    "- _Syntactic dependency parsing_ is a way of connecting words based on syntactic relationships, [such as](https://spacy.io/docs/api/annotation#dependency-parsing-english) `DOBJ` (direct object), `PREP` (prepositional modifier), or `POBJ` (object of preposition).\n",
    "    - Check out the dependency parse for the phrase [\"Send the report by Kyle by tomorrow\"](https://demos.explosion.ai/displacy/?text=Send%20the%20report%20by%20Kyle%20by%20tomorrow&model=en&cpu=1&cph=1) as an example\n",
    "\n",
    "#### Features\n",
    "The imperative mood centers around _actions_, and actions are generally represented in English using verbs. So the features are engineered to also center on the VERB:\n",
    "1. *FeatureName.VERB*: Does the phrase contain VERB(s) of the tag form VB*?\n",
    "2. *FeatureName.FOLLOWING_POS*: Are the words following the VERB(s) of certain parts of speech?\n",
    "3. *FeatureName.FOLLOWING_POSTAG*: Are the words following the VERB(s) of certain POS tags?\n",
    "4. *FeatureName.CHILD_DEP*: Are the VERB(s) parents of certain syntactic dependencies?\n",
    "5. *FeatureName.PARENT_DEP*: Are the VERB(s) children of certain syntactic dependencies?\n",
    "6. *FeatureName.CHILD_POS*: Are the syntactic dependencies that the VERB(s) are children of of certain parts of speech?\n",
    "7. *FeatureName.CHILD_POSTAG*: Are the syntactic dependencies that the VERB(s) are children of of certain POS tags?\n",
    "8. *FeatureName.PARENT_POS*: Are the syntactic dependencies that the VERB(s) parent of certain parts of speech?\n",
    "9. *FeatureName.PARENT_POSTAG*: Are the syntactic dependencies that the VERB(s) parent of certain POS tags?\n",
    "\n",
    "Note that features 2-9 all depend on feature 1 between `True`; if `False`, phrase vectorization will result in all zeroes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a recipe corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wrote and ran `epicurious_recipes.py`\\* to scrape Epicurious.com for recipe instructions and descriptions. Output is `epicurious-pos.txt` and `epicurious-neg.txt`.\n",
    "\n",
    "\\* _script (very) loosely based off of https://github.com/benosment/hrecipe-parse_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that deriving all negative examples in the training set from Epicurious recipe descriptions would result in negative examples that are longer and syntactically more complicated than the positive examples. This is a form of bias.\n",
    "\n",
    "To (hopefully?) correct for this a bit, I will add the short movie reviews found at https://pythonprogramming.net/static/downloads/short_reviews/ as more negative examples.\n",
    "\n",
    "This still feels weird because we're selecting negative examples only from specific categories of text (recipe descriptions, short movie reviews) - just because they're readily available.\n",
    "\n",
    "Ultimately though, this recipe corpus is a **stopgap/proof of concept** for a corpus more relevant to tasks later on, so I won't worry further about this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "pos_data_path = BASE_DIR + '/pos.txt'\n",
    "neg_data_path = BASE_DIR + '/neg.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(pos_data_path, 'r', encoding='utf-8') as f:\n",
    "    pos_data = f.read()\n",
    "with open(neg_data_path, 'r', encoding='utf-8') as f:\n",
    "    neg_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_data_split = pos_data.split('\\n')\n",
    "neg_data_split = neg_data.split('\\n')\n",
    "\n",
    "num_pos = len(pos_data_split)\n",
    "num_neg = len(neg_data_split)\n",
    "\n",
    "# 50/50 split between the number of positive and negative samples\n",
    "num = num_pos if num_pos < num_neg else num_neg\n",
    "\n",
    "# shuffle samples\n",
    "random.shuffle(pos_data_split)\n",
    "random.shuffle(neg_data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "for l in pos_data_split[:num]:\n",
    "    lines.append((l, 'pos'))\n",
    "for l in neg_data_split[:num]:\n",
    "    lines.append((l, 'neg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "class FeatureName(Enum):\n",
    "    VERB = auto()\n",
    "    FOLLOWING_POS = auto()\n",
    "    FOLLOWING_POSTAG = auto()\n",
    "    CHILD_DEP = auto()\n",
    "    PARENT_DEP = auto()\n",
    "    CHILD_POS = auto()\n",
    "    CHILD_POSTAG = auto()\n",
    "    PARENT_POS = auto()\n",
    "    PARENT_POSTAG = auto()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [spaCy.io](https://spacy.io/) for NLP\n",
    "_Because Stanford CoreNLP is hard to install for Python_\n",
    "\n",
    "Found Spacy through an article on [\"Training a Classifier for Relation Extraction from Medical Literature\"](https://www.microsoft.com/developerblog/2016/09/13/training-a-classifier-for-relation-extraction-from-medical-literature/) ([GitHub](https://github.com/CatalystCode/corpus-to-graph-ml))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"nltk_library_comparison.png\" alt=\"NLTK library comparison chart https://spacy.io/docs/api/#comparison\" style=\"width: 400px; margin: 0;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!conda config --add channels conda-forge\n",
    "#!conda install spacy\n",
    "#!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Spacy Data Model for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy's sentence segmentation is lacking... https://github.com/explosion/spaCy/issues/235. So each '\\n' will start a new Spacy Doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_spacy_docs(ll):\n",
    "    dd = [(nlp(l[0]), l[1]) for l in ll]\n",
    "    # collapse noun phrases into single compounds\n",
    "    for d in dd:\n",
    "        for np in d[0].noun_chunks:\n",
    "            np.merge(np.root.tag_, np.text, np.root.ent_type_)\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = create_spacy_docs(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization, POS tagging, and dependency parsing happened automatically with the `nlp(line)` calls above! So let's look at the outputs.\n",
    "\n",
    "https://spacy.io/docs/usage/data-model and https://spacy.io/docs/api/doc will be useful going forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Divide mushrooms and chickpeas into separate piles and spread in a single layer.]\n",
      "[Add 1 Tbsp. oil, then sugar snap peas, and shake pan so sugar snaps spread out in a single layer.]\n",
      "[Line a baking sheet with parchment paper.]\n",
      "[Let sit at room temperature 15 minutes before cooking.]\n",
      "[Tip into a bowl with the ground almonds and flour and mix together.]\n",
      "[After cooled, cut fritters into pieces to top cupcakes.]\n",
      "[Flip the chicken over and cook for 5 minutes more.]\n",
      "[In a second shallow bowl, combine the polenta, cheese, salt, and pepper.]\n",
      "[Drizzle with oil; season with salt and pepper.]\n",
      "[Roast, tossing occasionally, until golden brown, 10–12 minutes.]\n"
     ]
    }
   ],
   "source": [
    "for doc in docs[:10]:\n",
    "    print(list(doc[0].sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Divide mushrooms, chickpeas, separate piles, a single layer]\n",
      "[oil, pan, so sugar snaps, a single layer]\n",
      "[Line, a baking sheet, parchment paper]\n",
      "[room temperature, cooking]\n",
      "[Tip, a bowl, the ground almonds, flour]\n",
      "[fritters, pieces, top cupcakes]\n",
      "[the chicken, 5 minutes]\n",
      "[a second shallow bowl, the polenta]\n",
      "[Drizzle, oil, season, salt, pepper]\n",
      "[Roast, golden brown]\n"
     ]
    }
   ],
   "source": [
    "for doc in docs[:10]:\n",
    "    print(list(doc[0].noun_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Spacy's dependency graph visualization](https://demos.explosion.ai/displacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divide mushrooms nsubj Divide mushrooms NOUN NNS spread [and, chickpeas, into]\n",
      "and cc and CCONJ CC Divide mushrooms []\n",
      "chickpeas conj chickpeas NOUN NNS Divide mushrooms []\n",
      "into prep into ADP IN Divide mushrooms [separate piles]\n",
      "separate piles pobj separate piles NOUN NNS into [and]\n",
      "and cc and CCONJ CC separate piles []\n",
      "spread ROOT spread VERB VB spread [Divide mushrooms, in, .]\n",
      "in prep in ADP IN spread [a single layer]\n",
      "a single layer pobj a single layer NOUN NN in []\n",
      ". punct . PUNCT . spread []\n",
      "Add ROOT add VERB VB Add [1, Tbsp, ., oil, then, peas, and, shake, spread, .]\n",
      "1 nummod 1 NUM CD Add []\n",
      "Tbsp appos tbsp PROPN NNP Add []\n",
      ". punct . PUNCT . Add []\n",
      "oil dobj oil NOUN NN Add [,]\n",
      ", punct , PUNCT , oil []\n",
      "then advmod then ADV RB Add []\n",
      "sugar compound sugar NOUN NN snap []\n",
      "snap compound snap NOUN NN peas [sugar]\n",
      "peas dep pea NOUN NNS Add [snap, ,]\n",
      ", punct , PUNCT , peas []\n",
      "and cc and CCONJ CC Add []\n",
      "shake conj shake VERB VB Add [pan]\n",
      "pan dobj pan NOUN NN shake []\n",
      "so sugar snaps nsubj so sugar snaps NOUN NNS spread []\n",
      "spread conj spread VERB VBN Add [so sugar snaps, out, in]\n",
      "out prt out PART RP spread []\n",
      "in prep in ADP IN spread [a single layer]\n",
      "a single layer pobj a single layer NOUN NN in []\n",
      ". punct . PUNCT . Add []\n",
      "Line ROOT Line NOUN NN Line [a baking sheet, .]\n",
      "a baking sheet dobj a baking sheet NOUN NN Line [with]\n",
      "with prep with ADP IN a baking sheet [parchment paper]\n",
      "parchment paper pobj parchment paper NOUN NN with []\n",
      ". punct . PUNCT . Line []\n",
      "Let ROOT let VERB VB Let [sit, .]\n",
      "sit ccomp sit VERB VB Let [at, minutes]\n",
      "at prep at ADP IN sit [room temperature]\n",
      "room temperature pobj room temperature NOUN NN at []\n",
      "15 nummod 15 NUM CD minutes []\n",
      "minutes npadvmod minute NOUN NNS sit [15, before]\n",
      "before prep before ADP IN minutes [cooking]\n",
      "cooking pobj cooking NOUN NN before []\n",
      ". punct . PUNCT . Let []\n",
      "Tip nsubj Tip PROPN NNP mix [into]\n",
      "into prep into ADP IN Tip [a bowl]\n",
      "a bowl pobj a bowl NOUN NN into [with]\n",
      "with prep with ADP IN a bowl [the ground almonds]\n",
      "the ground almonds pobj the ground almonds NOUN NNS with [and, flour]\n",
      "and cc and CCONJ CC the ground almonds []\n",
      "flour conj flour NOUN NN the ground almonds [and]\n",
      "and cc and CCONJ CC flour []\n",
      "mix ROOT mix VERB VB mix [Tip, together, .]\n",
      "together advmod together ADV RB mix []\n",
      ". punct . PUNCT . mix []\n"
     ]
    }
   ],
   "source": [
    "for doc in docs[:5]:\n",
    "    for token in doc[0]:\n",
    "        print(token.text, token.dep_, token.lemma_, token.pos_, token.tag_, token.head, list(token.children))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def featurize(d):\n",
    "    s_features = defaultdict(int)\n",
    "    for idx, token in enumerate(d):\n",
    "        #print(token, token.pos_, token.tag_)\n",
    "        if re.match(r'VB.?', token.tag_) is not None: # note: not using token.pos == VERB because this also includes BES, HVS, MD tags \n",
    "            s_features[FeatureName.VERB.name] += 1\n",
    "            # FOLLOWING_POS\n",
    "            next_idx = idx + 1;\n",
    "            if next_idx < len(d):\n",
    "                s_features[f'{FeatureName.FOLLOWING_POS.name}_{d[next_idx].pos_}'] += 1\n",
    "                s_features[f'{FeatureName.FOLLOWING_POSTAG.name}_{d[next_idx].tag_}'] += 1\n",
    "            # VERB_HEAD_DEP\n",
    "            # VERB_HEAD_POS\n",
    "            '''\n",
    "            \"Because the syntactic relations form a tree, every word has exactly one head.\n",
    "            You can therefore iterate over the arcs in the tree by iterating over the words in the sentence.\"\n",
    "            https://spacy.io/docs/usage/dependency-parse#navigating\n",
    "            '''\n",
    "            if (token.head is not token):\n",
    "                s_features[f'{FeatureName.PARENT_DEP.name}_{token.head.dep_.upper()}'] += 1\n",
    "                s_features[f'{FeatureName.PARENT_POS.name}_{token.head.pos_}'] += 1\n",
    "                s_features[f'{FeatureName.PARENT_POSTAG.name}_{token.head.tag_}'] += 1\n",
    "            # VERB_CHILD_DEP\n",
    "            # VERB_CHILD_POS\n",
    "            for child in token.children:\n",
    "                s_features[f'{FeatureName.CHILD_DEP.name}_{child.dep_.upper()}'] += 1\n",
    "                s_features[f'{FeatureName.CHILD_POS.name}_{child.pos_}'] += 1\n",
    "                s_features[f'{FeatureName.CHILD_POSTAG.name}_{child.tag_}'] += 1\n",
    "    return dict(s_features)\n",
    "        #print(dict(s_features))\n",
    "    #print()\n",
    "\n",
    "#print(featuresets, len(featuresets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets = [(doc[0], (featurize(doc[0]), doc[1])) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats on number of features per example:\n",
      "mean: 23.019180470793373\n",
      "stdev: 14.696807269292922\n",
      "median: 23.0\n",
      "mode: 0\n",
      "max: 75\n",
      "min: 0\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean, median, mode, stdev\n",
    "f_lengths = [len(fs[1][0]) for fs in featuresets]\n",
    "\n",
    "print('Stats on number of features per example:')\n",
    "print(f'mean: {mean(f_lengths)}')\n",
    "print(f'stdev: {stdev(f_lengths)}')\n",
    "print(f'median: {median(f_lengths)}')\n",
    "print(f'mode: {mode(f_lengths)}')\n",
    "print(f'max: {max(f_lengths)}')\n",
    "print(f'min: {min(f_lengths)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Divide mushrooms and chickpeas into separate piles and spread in a single layer.,\n",
       "  ({'CHILD_DEP_NSUBJ': 1,\n",
       "    'CHILD_DEP_PREP': 1,\n",
       "    'CHILD_DEP_PUNCT': 1,\n",
       "    'CHILD_POSTAG_.': 1,\n",
       "    'CHILD_POSTAG_IN': 1,\n",
       "    'CHILD_POSTAG_NNS': 1,\n",
       "    'CHILD_POS_ADP': 1,\n",
       "    'CHILD_POS_NOUN': 1,\n",
       "    'CHILD_POS_PUNCT': 1,\n",
       "    'FOLLOWING_POSTAG_IN': 1,\n",
       "    'FOLLOWING_POS_ADP': 1,\n",
       "    'VERB': 1},\n",
       "   'pos')),\n",
       " (Add 1 Tbsp. oil, then sugar snap peas, and shake pan so sugar snaps spread out in a single layer.,\n",
       "  ({'CHILD_DEP_ADVMOD': 1,\n",
       "    'CHILD_DEP_APPOS': 1,\n",
       "    'CHILD_DEP_CC': 1,\n",
       "    'CHILD_DEP_CONJ': 2,\n",
       "    'CHILD_DEP_DEP': 1,\n",
       "    'CHILD_DEP_DOBJ': 2,\n",
       "    'CHILD_DEP_NSUBJ': 1,\n",
       "    'CHILD_DEP_NUMMOD': 1,\n",
       "    'CHILD_DEP_PREP': 1,\n",
       "    'CHILD_DEP_PRT': 1,\n",
       "    'CHILD_DEP_PUNCT': 2,\n",
       "    'CHILD_POSTAG_.': 2,\n",
       "    'CHILD_POSTAG_CC': 1,\n",
       "    'CHILD_POSTAG_CD': 1,\n",
       "    'CHILD_POSTAG_IN': 1,\n",
       "    'CHILD_POSTAG_NN': 2,\n",
       "    'CHILD_POSTAG_NNP': 1,\n",
       "    'CHILD_POSTAG_NNS': 2,\n",
       "    'CHILD_POSTAG_RB': 1,\n",
       "    'CHILD_POSTAG_RP': 1,\n",
       "    'CHILD_POSTAG_VB': 1,\n",
       "    'CHILD_POSTAG_VBN': 1,\n",
       "    'CHILD_POS_ADP': 1,\n",
       "    'CHILD_POS_ADV': 1,\n",
       "    'CHILD_POS_CCONJ': 1,\n",
       "    'CHILD_POS_NOUN': 4,\n",
       "    'CHILD_POS_NUM': 1,\n",
       "    'CHILD_POS_PART': 1,\n",
       "    'CHILD_POS_PROPN': 1,\n",
       "    'CHILD_POS_PUNCT': 2,\n",
       "    'CHILD_POS_VERB': 2,\n",
       "    'FOLLOWING_POSTAG_CD': 1,\n",
       "    'FOLLOWING_POSTAG_NN': 1,\n",
       "    'FOLLOWING_POSTAG_RP': 1,\n",
       "    'FOLLOWING_POS_NOUN': 1,\n",
       "    'FOLLOWING_POS_NUM': 1,\n",
       "    'FOLLOWING_POS_PART': 1,\n",
       "    'PARENT_DEP_ROOT': 2,\n",
       "    'PARENT_POSTAG_VB': 2,\n",
       "    'PARENT_POS_VERB': 2,\n",
       "    'VERB': 3},\n",
       "   'pos'))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On one run, the above line printed the following featureset:\n",
    "`(Gather foil loosely on top and bake for 1 1/2 hours., ({}, 'pos'))`\n",
    "\n",
    "This is because the Spacy.io POS tagger provided this:\n",
    "   `Gather/NNP foil/NN loosely/RB on/IN top/NN and/CC bake/NN for/IN 1 1/2 hours./NNS`\n",
    "\n",
    "With no VERBs tagged, which is incorrect.\n",
    "\n",
    "---\n",
    "Compare to [Stanford CoreNLP POS tagger](http://nlp.stanford.edu:8080/corenlp/process):\n",
    "   `Gather/VB foil/NN loosely/RB on/IN top/JJ and/CC bake/VB for/IN 1 1/2/CD hours/NNS ./.`\n",
    "\n",
    "And [Stanford Parser](http://nlp.stanford.edu:8080/parser/index.jsp):\n",
    "   `Gather/NNP foil/VB loosely/RB on/IN top/NN and/CC bake/VB for/IN 1 1/2/CD hours/NNS ./.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training samples: 1835\n",
      "# test samples: 459\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(featuresets)\n",
    "\n",
    "split_num = round(num / 5)\n",
    "\n",
    "print(f'# training samples: {num-split_num}')\n",
    "print(f'# test samples: {split_num}')\n",
    "\n",
    "# train and test sets\n",
    "testing_set = [fs[1] for i, fs in enumerate(featuresets[:split_num])]\n",
    "training_set =  [fs[1] for i, fs in enumerate(featuresets[split_num:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decoupling the functionality of nltk.classify.accuracy\n",
    "def predict(classifier, gold, prob=True):\n",
    "    if (prob is True):\n",
    "        predictions = classifier.prob_classify_many([fs for (fs, ll) in gold])\n",
    "    else:\n",
    "        predictions = classifier.classify_many([fs for (fs, ll) in gold])\n",
    "    return list(zip(predictions, [ll for (fs, ll) in gold]))\n",
    "\n",
    "def accuracy(predicts, prob=True):\n",
    "    if (prob is True):\n",
    "        correct = [label == prediction.max() for (prediction, label) in predicts]\n",
    "    else:\n",
    "        correct = [label == prediction for (prediction, label) in predicts]\n",
    "        \n",
    "    if correct:\n",
    "        return sum(correct) / len(correct)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note below the use of `DummyClassifier` to provide a simple sanity check, a baseline of random predictions. `stratified` means it \"generates random predictions by respecting the training set class distribution.\" (http://scikit-learn.org/stable/modules/model_evaluation.html#dummy-estimators)\n",
    "\n",
    "> More generally, when the accuracy of a classifier is too close to random, it probably means that something went wrong: features are not helpful, a hyperparameter is not correctly tuned, the classifier is suffering from class imbalance, etc…\n",
    "\n",
    "If a classifier can beat the `DummyClassifier`, it is at least learning something valuable! How valuable is another question..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier accuracy percent: 52.28758169934641\n",
      "NaiveBayes classifier accuracy percent: 63.61655773420479\n",
      "MultinomialNB classifier accuracy percent: 80.3921568627451\n",
      "BernoulliNB classifier accuracy percent: 76.25272331154684\n",
      "LogisticRegression classifier accuracy percent: 85.18518518518519\n",
      "SGD classifier accuracy percent: 74.7276688453159\n",
      "SVC classifier accuracy percent: 84.31372549019608\n",
      "LinearSVC classifier accuracy percent: 85.40305010893246\n",
      "DecisionTree classifier accuracy percent: 79.08496732026144\n"
     ]
    }
   ],
   "source": [
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.classify.decisiontree import DecisionTreeClassifier\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "dummy = SklearnClassifier(DummyClassifier(strategy='stratified', random_state=0))\n",
    "dummy.train(training_set)\n",
    "dummy_predict = predict(dummy, testing_set)\n",
    "dummy_accuracy = accuracy(dummy_predict)\n",
    "print(\"Dummy classifier accuracy percent:\", dummy_accuracy*100)\n",
    "\n",
    "nb = NaiveBayesClassifier.train(training_set)\n",
    "nb_predict = predict(nb, testing_set)\n",
    "nb_accuracy = accuracy(nb_predict)\n",
    "print(\"NaiveBayes classifier accuracy percent:\", nb_accuracy*100)\n",
    "\n",
    "multinomial_nb = SklearnClassifier(MultinomialNB())\n",
    "multinomial_nb.train(training_set)\n",
    "mnb_predict = predict(multinomial_nb, testing_set)\n",
    "mnb_accuracy = accuracy(mnb_predict)\n",
    "print(\"MultinomialNB classifier accuracy percent:\", mnb_accuracy*100)\n",
    "\n",
    "bernoulli_nb = SklearnClassifier(BernoulliNB())\n",
    "bernoulli_nb.train(training_set)\n",
    "bnb_predict = predict(bernoulli_nb, testing_set)\n",
    "bnb_accuracy = accuracy(bnb_predict)\n",
    "print(\"BernoulliNB classifier accuracy percent:\", bnb_accuracy*100)\n",
    "\n",
    "# ??logistic_regression._clf\n",
    "#   sklearn.svm.LinearSVC : learns SVM models using the same algorithm.\n",
    "logistic_regression = SklearnClassifier(LogisticRegression())\n",
    "logistic_regression.train(training_set)\n",
    "lr_predict = predict(logistic_regression, testing_set)\n",
    "lr_accuracy = accuracy(lr_predict)\n",
    "print(\"LogisticRegression classifier accuracy percent:\", lr_accuracy*100)\n",
    "\n",
    "# ??sgd._clf\n",
    "#    The 'log' loss gives logistic regression, a probabilistic classifier.\n",
    "# ??linear_svc._clf\n",
    "#   can optimize the same cost function as LinearSVC\n",
    "#   by adjusting the penalty and loss parameters. In addition it requires\n",
    "#   less memory, allows incremental (online) learning, and implements\n",
    "#   various loss functions and regularization regimes.\n",
    "sgd = SklearnClassifier(SGDClassifier(loss='log'))\n",
    "sgd.train(training_set)\n",
    "sgd_predict = predict(sgd, testing_set)\n",
    "sgd_accuracy = accuracy(sgd_predict)\n",
    "print(\"SGD classifier accuracy percent:\", sgd_accuracy*100)\n",
    "\n",
    "# using libsvm with kernel 'rbf' (radial basis function)\n",
    "svc = SklearnClassifier(SVC(probability=True))\n",
    "svc.train(training_set)\n",
    "svc_predict = predict(svc, testing_set)\n",
    "svc_accuracy = accuracy(svc_predict)\n",
    "print(\"SVC classifier accuracy percent:\", svc_accuracy*100)\n",
    "\n",
    "# ??linear_svc._clf\n",
    "#    Similar to SVC with parameter kernel='linear', but implemented in terms of\n",
    "#    liblinear rather than libsvm, so it has more flexibility in the choice of\n",
    "#    penalties and loss functions and should scale better to large numbers of\n",
    "#    samples.\n",
    "#    Prefer dual=False when n_samples > n_features.\n",
    "linear_svc = SklearnClassifier(LinearSVC(dual=False))\n",
    "linear_svc.train(training_set)\n",
    "linear_svc_predict = predict(linear_svc, testing_set, False)\n",
    "linear_svc_accuracy = accuracy(linear_svc_predict, False)\n",
    "print(\"LinearSVC classifier accuracy percent:\", linear_svc_accuracy*100)\n",
    "\n",
    "# slow\n",
    "dt = DecisionTreeClassifier.train(training_set)\n",
    "dt_predict = predict(dt, testing_set, False)\n",
    "dt_accuracy = accuracy(dt_predict, False)\n",
    "print(\"DecisionTree classifier accuracy percent:\", dt_accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD: Multiple Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sgd` classifiers improves with epochs. `??sgd._clf` tells us that the default number of epochs `n_iter` is 5. So let's run more epochs. Also not that the training_set shuffle is `True` by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier classifier accuracy percent (epochs: 1000): 84.9673202614379\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "sgd = SklearnClassifier(SGDClassifier(loss='log', n_iter=num_epochs))\n",
    "sgd.train(training_set)\n",
    "sgd_predict = predict(sgd, testing_set)\n",
    "sgd_accuracy = accuracy(sgd_predict)\n",
    "print(f\"SGDClassifier classifier accuracy percent (epochs: {num_epochs}):\", sgd_accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, 1000 epochs run very quickly! And `SGDClassifier` performance has improved with more iterations.\n",
    "\n",
    "_Also note that we can set `warm_start` to `True` if we want to take advantage of online learning and reuse the solution of the previous call._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to scope analysis down to our top-performing classifiers, which consistently perform with >80% accuracy: `LogisticRegression`, `SVC`, `LinearSVC`, and `SGD`.\n",
    "\n",
    "We'll also include `Dummy` as a baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Omit `LinearSVC`? Since we have `SVC` performing well, and `LinearSVC` does not provide probability estimates. (However, `LinearSVC` is meant to \"scale better to large numbers of samples\" - i.e., `LinearSVC` is faster, as I've witnessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance on sample tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy: [('pos', 1.0), ('pos', 1.0), ('pos', 1.0), ('pos', 1.0), ('neg', 0.0), ('pos', 1.0), ('neg', 0.0)]\n",
      "LogisticRegression: [('pos', 0.57787315917563198), ('pos', 0.71976787805644704), ('pos', 0.90202359673281007), ('pos', 0.71976787805644704), ('pos', 0.87517196834667843), ('pos', 0.71976787805644704), ('pos', 0.74962733388797642)]\n",
      "SVC: [('pos', 0.78337496136116336), ('pos', 0.7371123757061474), ('pos', 0.84387550274254164), ('pos', 0.7371123757061474), ('pos', 0.81730958890799943), ('pos', 0.7371123757061474), ('pos', 0.77492180934221044)]\n",
      "LinearSVC: ['pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos']\n",
      "SGD: [('pos', 0.57554835689985495), ('pos', 0.73170163923160192), ('pos', 0.91605868461901896), ('pos', 0.73170163923160192), ('pos', 0.90172719947511659), ('pos', 0.73170163923160192), ('pos', 0.76426341375478135)]\n"
     ]
    }
   ],
   "source": [
    "sample_tasks = [\"Mow lawn\", \"Mow the lawn\", \"Buy new shoes\", \"Feed the dog\", \"Send report to Kyle\", \"Send the report to Kyle\", \"Peel the potatoes\"]\n",
    "features = [featurize(nlp(task)) for task in sample_tasks]\n",
    "\n",
    "tasks_dummy = [(l, p.prob('pos')*1.0) for l, p in zip(dummy.classify_many(features), dummy.prob_classify_many(features))]\n",
    "tasks_logistic = [(l, p.prob('pos')) for l,p in zip(logistic_regression.classify_many(features), logistic_regression.prob_classify_many(features))]\n",
    "tasks_svc = [(l, p.prob('pos')) for l,p in zip(svc.classify_many(features), svc.prob_classify_many(features))]\n",
    "tasks_linear_svc = linear_svc.classify_many(features)\n",
    "tasks_sgd = [(l, p.prob('pos')) for l,p in zip(sgd.classify_many(features), sgd.prob_classify_many(features))]\n",
    "\n",
    "print(f'Dummy: {tasks_dummy}')\n",
    "print(f'LogisticRegression: {tasks_logistic}')\n",
    "print(f'SVC: {tasks_svc}')\n",
    "print(f'LinearSVC: {tasks_linear_svc}')\n",
    "print(f'SGD: {tasks_sgd}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: `LinearSVC` is not implemented to provide probability estimates (https://github.com/scikit-learn/scikit-learn/issues/4820)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** tabular format would be cool above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Performance on prototype feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most Informative Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/11140887\n",
    "def show_most_informative_features(vectorizer, clf, n=20):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:round(n/2)], coefs_with_fns[:-(round(n/2) + 1):-1])\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        print(\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD\n",
      "\t-2.9453\tCHILD_DEP_AGENT\t\t2.5849\tCHILD_POSTAG_-RRB-\n",
      "\t-2.5896\tFOLLOWING_POSTAG_WRB\t\t1.9425\tPARENT_POS_PROPN\n",
      "\t-2.5486\tPARENT_DEP_AMOD\t\t1.9425\tPARENT_POSTAG_NNP\n",
      "\t-2.4047\tCHILD_DEP_INTJ \t\t1.7827\tPARENT_DEP_ADVMOD||CONJ\n",
      "\t-2.3380\tCHILD_POSTAG_``\t\t1.7600\tFOLLOWING_POSTAG_NFP\n",
      "\t-2.1528\tFOLLOWING_POSTAG_-RRB-\t\t1.6705\tFOLLOWING_POSTAG_RBS\n",
      "\t-1.9480\tCHILD_POSTAG_HYPH\t\t1.6692\tCHILD_DEP_ADVMOD||XCOMP\n",
      "\t-1.6555\tCHILD_POSTAG_''\t\t1.6173\tCHILD_DEP_NPADVMOD\n",
      "\n",
      "Logistic Regression\n",
      "\t-2.4040\tCHILD_DEP_AGENT\t\t2.0140\tCHILD_POSTAG_-RRB-\n",
      "\t-1.7055\tPARENT_DEP_AMOD\t\t1.4831\tCHILD_DEP_NPADVMOD\n",
      "\t-1.6710\tCHILD_POSTAG_HYPH\t\t1.4637\tPARENT_POS_PROPN\n",
      "\t-1.6442\tFOLLOWING_POSTAG_WRB\t\t1.4637\tPARENT_POSTAG_NNP\n",
      "\t-1.5683\tCHILD_DEP_INTJ \t\t1.1580\tVERB           \n",
      "\t-1.5185\tCHILD_POSTAG_``\t\t1.0738\tCHILD_POS_PROPN\n",
      "\t-1.4930\tCHILD_DEP_NSUBJ\t\t1.0508\tCHILD_POSTAG_NNP\n",
      "\t-1.4131\tPARENT_POSTAG_VBZ\t\t1.0454\tCHILD_DEP_DOBJ||XCOMP\n",
      "\n",
      "LinearSVC\n",
      "\t-1.4346\tFOLLOWING_POSTAG_WRB\t\t1.5444\tPARENT_DEP_ADVMOD||CONJ\n",
      "\t-1.4069\tCHILD_POSTAG_``\t\t1.3265\tFOLLOWING_POSTAG_NFP\n",
      "\t-1.2810\tFOLLOWING_POSTAG_-RRB-\t\t1.2377\tFOLLOWING_POSTAG_RBS\n",
      "\t-1.2391\tPARENT_DEP_AMOD\t\t1.1160\tCHILD_POSTAG_-RRB-\n",
      "\t-1.2309\tCHILD_DEP_AGENT\t\t1.1155\tCHILD_POSTAG_XX\n",
      "\t-1.1576\tCHILD_DEP_INTJ \t\t1.0616\tCHILD_DEP_ADVMOD||XCOMP\n",
      "\t-1.0911\tPARENT_DEP_DET \t\t1.0261\tPARENT_DEP_DOBJ||XCOMP\n",
      "\t-0.8060\tCHILD_POS_PUNCT\t\t0.9963\tPARENT_POS_PROPN\n"
     ]
    }
   ],
   "source": [
    "print('SGD')\n",
    "show_most_informative_features(sgd._vectorizer, sgd._clf, 15)\n",
    "print()\n",
    "print('Logistic Regression')\n",
    "show_most_informative_features(logistic_regression._vectorizer, logistic_regression._clf, 15)\n",
    "print()\n",
    "print('LinearSVC')\n",
    "show_most_informative_features(linear_svc._vectorizer, linear_svc._clf, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: Because `SVC` is using the nonlinear RBF kernel, we cannot show the most informative features (`coef_ is only available when using a linear kernel`).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Provide meaning behind these features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit Learn metrics: Confusion matrix, Classification report, F1 score, Log loss\n",
    "\n",
    "http://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def classification_report(predict, prob=True):\n",
    "    predictions, labels = zip(*predict)\n",
    "    if prob is True:\n",
    "        return metrics.classification_report(labels, [p.max() for p in predictions])\n",
    "    else:\n",
    "        return metrics.classification_report(labels, predictions)\n",
    "\n",
    "def confusion_matrix(predict, prob=True, print_layout=False):\n",
    "    predictions, labels = zip(*predict)\n",
    "    if print_layout is True:\n",
    "        print('Layout\\n[[tn   fp]\\n [fn   tp]]\\n')\n",
    "    if prob is True:\n",
    "        return metrics.confusion_matrix(labels, [p.max() for p in predictions])\n",
    "    else:\n",
    "        return metrics.confusion_matrix(labels, predictions)\n",
    "\n",
    "def log_loss(predict):\n",
    "    predictions, labels = zip(*predict)\n",
    "    return metrics.log_loss(labels, [p.prob('pos') for p in predictions])\n",
    "\n",
    "def roc_auc_score(predict):\n",
    "    predictions, labels = zip(*predict)\n",
    "    # need to convert labels to binary classification of 0 or 1\n",
    "    return metrics.roc_auc_score([1 if l == 'pos' else 0 for l in labels], [p.prob('pos') for p in predictions], average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.89      0.79      0.84       226\n",
      "        pos       0.82      0.91      0.86       233\n",
      "\n",
      "avg / total       0.85      0.85      0.85       459\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.90      0.78      0.84       226\n",
      "        pos       0.81      0.92      0.86       233\n",
      "\n",
      "avg / total       0.86      0.85      0.85       459\n",
      "\n",
      "\n",
      "SVC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.87      0.80      0.83       226\n",
      "        pos       0.82      0.89      0.85       233\n",
      "\n",
      "avg / total       0.85      0.84      0.84       459\n",
      "\n",
      "\n",
      "LinearSVC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.90      0.79      0.84       226\n",
      "        pos       0.82      0.92      0.86       233\n",
      "\n",
      "avg / total       0.86      0.85      0.85       459\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('SGD')\n",
    "print(classification_report(sgd_predict))\n",
    "print()\n",
    "print('Logistic Regression')\n",
    "print(classification_report(lr_predict))\n",
    "print()\n",
    "print('SVC')\n",
    "print(classification_report(svc_predict))\n",
    "print()\n",
    "print('LinearSVC')\n",
    "print(classification_report(linear_svc_predict, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layout\n",
      "[[tn   fp]\n",
      " [fn   tp]]\n",
      "\n",
      "SGD\n",
      "[[178  48]\n",
      " [ 21 212]]\n",
      "\n",
      "Logistic Regression\n",
      "[[177  49]\n",
      " [ 19 214]]\n",
      "\n",
      "SVC\n",
      "[[180  46]\n",
      " [ 26 207]]\n",
      "\n",
      "LinearSVC\n",
      "[[178  48]\n",
      " [ 19 214]]\n"
     ]
    }
   ],
   "source": [
    "print('Layout\\n[[tn   fp]\\n [fn   tp]]\\n')\n",
    "\n",
    "print('SGD')\n",
    "print(confusion_matrix(sgd_predict))\n",
    "print()\n",
    "print('Logistic Regression')\n",
    "print(confusion_matrix(lr_predict))\n",
    "print()\n",
    "print('SVC')\n",
    "print(confusion_matrix(svc_predict))\n",
    "print()\n",
    "print('LinearSVC')\n",
    "print(confusion_matrix(linear_svc_predict, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower the better for `log_loss`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD: 0.35720755386910946\n",
      "Logistic Regression: 0.35259513950041504\n",
      "SVC: 0.3785530776608165\n"
     ]
    }
   ],
   "source": [
    "print(f'SGD: {log_loss(sgd_predict)}')\n",
    "print(f'Logistic Regression: {log_loss(lr_predict)}')\n",
    "print(f'SVC: {log_loss(svc_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher the better for `roc_auc_score`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD: 0.9199361920316002\n",
      "Logistic Regression: 0.9223479813133808\n",
      "SVC: 0.9070986364844847\n"
     ]
    }
   ],
   "source": [
    "print(f'SGD: {roc_auc_score(sgd_predict)}')\n",
    "print(f'Logistic Regression: {roc_auc_score(lr_predict)}')\n",
    "print(f'SVC: {roc_auc_score(svc_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: We cannot compute `log_loss` or `roc_auc_score` for `LinearSVC` because it does not provide probability estimates.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next up**: digging into the results (confusion matrix, most informative features), comparing results to LUIS model, cross validation/grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps and Improvements\n",
    "\n",
    "1. Training set may be too specific/not relevant enough (recipe instructions for positive dataset, recipe descriptions+short movie reviews for negative dataset)\n",
    "2. Throwing features into a blender - need to understand value of each\n",
    "3. Need to review different classifiers, strengths/weaknesses\n",
    "4. Phrase vectorizations of all 0s\n",
    "5. Varying feature vector lengths\n",
    "6. Voting\n",
    "7. Reducing dimensionality using most informative feature information\n",
    "8. Combining verb phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things abandoned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I needed a library that supports dependency parsing, which NLTK does not... so I thought I'd add the [Stanford CoreNLP](https://stanfordnlp.github.io/CoreNLP/) toolkit and [its associated software](https://nlp.stanford.edu/software/) to NLTK. However, there are many conflicting instructions for installing the Java-based project, depending on NLTK version used. By the time I figured this out, the installation had become a time sink. So I abandoned this effort in favor of Spacy.io.\n",
    "\n",
    "I might return this way if I want to improve results/implement a voter system between the various linguistic and classification methods later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = [s for l in lines for s in sent_tokenize(l)] # punkt\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_sentences = []\n",
    "for s in sentences:\n",
    "    words = word_tokenize(s)\n",
    "    tagged = nltk.pos_tag(words) # averaged_perceptron_tagger\n",
    "    tagged_sentences.append(tagged)\n",
    "print(tagged_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: POS accuracy\n",
    "\n",
    "`Run down to the shop, will you, Peter` is parsed unexpectedly by `nltk.pos_tag`:\n",
    "> `[('Run', 'NNP'), ('down', 'RB'), ('to', 'TO'), ('the', 'DT'), ('shop', 'NN'), (',', ','), ('will', 'MD'), ('you', 'PRP'), (',', ','), ('Peter', 'NNP')]`\n",
    "\n",
    "`Run` is tagged as a `NNP (proper noun, singular)`\n",
    "\n",
    "I expected an output more like what the [Stanford Parser](http://nlp.stanford.edu:8080/parser/) provides:\n",
    "> `Run/VBG down/RP to/TO the/DT shop/NN ,/, will/MD you/PRP ,/, Peter/NNP`\n",
    "\n",
    "`Run` is tagged as a `VGB (verb, gerund/present participle)` - still not quite the `VB` I want, but at least it's a `V*`\n",
    "\n",
    "_MEANWHILE..._\n",
    "\n",
    "`nltk.pos_tag` did better with:\n",
    "> `[('Do', 'VB'), ('not', 'RB'), ('clean', 'VB'), ('soot', 'NN'), ('off', 'IN'), ('the', 'DT'), ('window', 'NN')]`\n",
    "\n",
    "Compared to [Stanford CoreNLP](http://nlp.stanford.edu:8080/corenlp/process) (note that this is different than what [Stanford Parser](http://nlp.stanford.edu:8080/parser/) outputs):\n",
    "> `(ROOT (S (VP (VB Do) (NP (RB not) (JJ clean) (NN soot)) (PP (IN off) (NP (DT the) (NN window))))))`\n",
    "\n",
    "Concern: _clean_ as `VB (verb, base form)` vs `JJ (adjective)` \n",
    "\n",
    "**IMPROVE** POS taggers should vote: nltk.pos_tag (averaged_perceptron_tagger), Stanford Parser, CoreNLP, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note what Spacy POS tagger did with `Run down to the shop, will you Peter`:\n",
    "\n",
    "`Run/VB down/RP to/IN the shop/NN ,/, will/MD you/PRP ,/, Peter/NNP`\n",
    "\n",
    "    where `Run` is the `VB` I expected from POS tagging (compared to `nltk.pos_tag` result of `NNP`). Also note that Spacy collapses `the shop` into a single unit, which should be helpful during featurization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "featuresets = []\n",
    "for ts in tagged_sentences:\n",
    "    s_features = defaultdict(int)\n",
    "    for idx, tup in enumerate(ts):\n",
    "        #print(tup)\n",
    "        pos = tup[1]\n",
    "        # FeatureName.VERB\n",
    "        is_verb = re.match(r'VB.?', pos) is not None\n",
    "        print(tup, is_verb)\n",
    "        if is_verb:\n",
    "            s_features[FeatureName.VERB] += 1\n",
    "            # FOLLOWING_POS\n",
    "            next_idx = idx + 1;\n",
    "            if next_idx < len(ts):\n",
    "                s_features[f'{FeatureName.FOLLOWING}_{ts[next_idx][1]}'] += 1\n",
    "            # VERB_MODIFIER\n",
    "            # VERB_MODIFYING\n",
    "        else:\n",
    "            s_features[FeatureName.VERB] = 0\n",
    "    featuresets.append(dict(s_features))\n",
    "\n",
    "print()\n",
    "print(featuresets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Stanford NLP](https://nlp.stanford.edu/software/)\n",
    "Setup guide used: https://stackoverflow.com/a/34112695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get dependency parser, NER, POS tagger\n",
    "!wget https://nlp.stanford.edu/software/stanford-parser-full-2017-06-09.zip\n",
    "!wget https://nlp.stanford.edu/software/stanford-ner-2017-06-09.zip\n",
    "!wget https://nlp.stanford.edu/software/stanford-postagger-full-2017-06-09.zip\n",
    "!unzip stanford-parser-full-2017-06-09.zip\n",
    "!unzip stanford-ner-2017-06-09.zip\n",
    "!unzip stanford-postagger-full-2017-06-09.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.parse.stanford import StanfordParser\n",
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "from nltk.parse.stanford import StanfordNeuralDependencyParser\n",
    "from nltk.tag.stanford import StanfordPOSTagger, StanfordNERTagger\n",
    "from nltk.tokenize.stanford import StanfordTokenizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
